{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Documentation for kmer-ord","text":"<p>Documentation is still under development, bare with us</p> <p>This documentation describes a toolkit for computing, normalising, and ordinating k-mer count data for exploratory analysis of long-read sequencing datasets or assembled contigs.</p> <p>The workflow consists of:</p> <ul> <li> Generating k-mer count matrices</li> <li> Applying appropriate normalisation for compositional data</li> <li> Performing dimensionality reduction</li> <li> Inspecting embeddings structure and binning</li> </ul>"},{"location":"#documentation-structure","title":"Documentation structure","text":"<ul> <li> <p> Getting started</p> <p>Install dependencies and set up environment</p> <p> Installation</p> <p> Quickstart</p> </li> <li> <p> Reference</p> <p>Complete command-line and parameter documentation for each script</p> <p> Reference</p> </li> <li> <p> Tutorials</p> <p>Practical guides for common workflows and analyses</p> <p> Tutorials</p> </li> <li> <p> Concepts</p> <p>Background material explaining why certain steps are required and how to interpret results.</p> <p> Concepts</p> <p> Glossary</p> <p> FAQ</p> </li> </ul>"},{"location":"glossary/","title":"Glossary","text":"<p>placeholder for glossary</p>"},{"location":"installation/","title":"installation","text":""},{"location":"quickstart/","title":"Quickstart","text":"<p>This quickstart walks through a minimal end-to-end workflow: from a set of sequences to a low-dimensional ordination based on k-mer counts.</p> <p>The example assumes a multi-FASTA input file and produces 2D embeddings suitable for visualisation.</p>"},{"location":"quickstart/#1-generate-a-k-mer-count-matrix","title":"1. Generate a k-mer count matrix","text":"<p>First, generate a k-mer count matrix from one or more FASTA files.</p> <p>Example:</p> <pre><code>python kmer-counting.py \\\n  --input input.fasta \\\n  --k 6 \\\n  --output 6mer\n</code></pre> <p>This produces a tab-separated matrix where:</p> <ul> <li>Rows correspond to samples (reads, contigs, or assemblies)</li> <li>Columns correspond to k-mers</li> <li>Values are raw k-mer counts</li> </ul> <p>For details on input formats and parameters, see: <code>kmer_counting.py</code>(reference/kmer_counting.md)</p>"},{"location":"quickstart/#2-run-ordination-on-the-k-mer-matrix","title":"2. Run ordination on the k-mer matrix","text":"<p>Next, perform dimensionality reduction on the k-mer count matrix.</p> <p>Minimal example using UMAP with default settings:</p> <pre><code>python kmer-ord.py \\\n  --input kmer_matrix.tsv \\\n  --methods umap\n</code></pre> <p>This will:</p> <ul> <li>Apply CLR normalisation by default</li> <li>Compute a 2D UMAP embedding</li> <li>Write the result to a projections/ directory next to the input file</li> </ul>"},{"location":"quickstart/#3-running-multiple-methods","title":"3. Running multiple methods","text":"<p>You can run multiple ordination methods in a single command:</p> <pre><code>python kmer-ord.py \\\n  --input kmer_matrix.tsv \\\n  --methods pca tsne umap trimap\n</code></pre> <p>Each method is applied independently, and results are written as separate output files.</p>"},{"location":"quickstart/#4-choosing-normalisation","title":"4. Choosing normalisation","text":"<p>k-mer count matrices are compositional because total counts depend on sequence length. Normalisation is therefore recommended.</p> <p>By default, Centered Log-Ratio (CLR) normalisation is applied. Alternative strategies can be specified:</p> <pre><code>python kmer-ord.py \\\n  --input kmer_matrix.tsv \\\n  --methods umap \\\n  --normalisation tss log_tss\n</code></pre> <p>Each normalisation method is applied independently.</p> <p>See: Concepts: Compositional data</p>"},{"location":"quickstart/#5-pca-pre-reduction-optional","title":"5. PCA pre-reduction (optional)","text":"<p>For high-dimensional matrices, PCA can be applied prior to nonlinear embedding:</p> <pre><code>python kmer-ord.py \\\n  --input kmer_matrix.tsv \\\n  --methods umap tsne \\\n  --pca_dim_red \\\n  --keep_variance 0.9\n</code></pre> <p>This reduces dimensionality while retaining 90% of the variance before embedding.</p>"},{"location":"quickstart/#6-scaling-to-dataset-size","title":"6. Scaling to dataset size","text":"<p>For larger datasets, scale-aware presets can be used:</p> <pre><code>python kmer-ord.py \\\n  --input kmer_matrix.tsv \\\n  --methods umap \\\n  --scale large\n</code></pre> <p>Available scale categories are: <code>default</code>, <code>small</code>, <code>medium</code>, <code>large</code>, or <code>auto</code></p>"},{"location":"quickstart/#output","title":"Output","text":"<p>All embeddings are written as TSV files containing one column per embedding dimension. Output filenames encode:</p> <ul> <li>Embedding dimensionality</li> <li>Normalisation method</li> <li>Ordination method</li> <li>Optional PCA settings</li> </ul>"},{"location":"quickstart/#whats-next","title":"What's next?","text":"<ul> <li>Explore parameter screening for method tuning</li> <li>Inspect concepts pages for interpretation guidance</li> <li>Follow tutorials for complete analysis workflows</li> </ul>"},{"location":"concepts/","title":"index for cocepts","text":""},{"location":"concepts/compositional_data/","title":"Compositional data","text":""},{"location":"concepts/compositional_data/#normalisation-methods","title":"Normalisation methods","text":""},{"location":"concepts/compositional_data/#centered-log-ratio-clr-transformation","title":"Centered log-ratio (CLR) transformation","text":"\\[ \\operatorname{clr}(x_i) = \\log\\left(\\frac{x_i}{g(\\mathbf{x})}\\right), \\qquad g(\\mathbf{x}) = \\left( \\prod_{j=1}^{D} x_j \\right)^{1/D} \\] <p>where</p> <ul> <li>\\( \\mathbf{x} = (x_1, \\dots, x_D) \\) is the k-mer count vector for a single sample  </li> <li>\\( x_i \\) is the count of the \\(i\\)-th k-mer  </li> <li>\\( D \\) is the total number of k-mers  </li> <li>\\( g(\\mathbf{x}) \\) is the geometric mean of the components of \\( \\mathbf{x} \\)</li> </ul>"},{"location":"concepts/compositional_data/#total-sum-scaling-tss","title":"Total Sum Scaling (TSS)","text":"<p>TSS normalizes each sample to unit sum, removing sequencing depth effects.</p> \\[ x_i^{\\mathrm{TSS}} = \\frac{x_i}{\\sum_{j=1}^{D} x_j} \\] <p>where</p> <ul> <li>\\( x_i \\) is the count of the \\(i\\)-th k-mer  </li> <li>\\( D \\) is the number of k-mers  </li> <li>\\( \\sum_{j=1}^{D} x_j \\) is the total count of all k-mers in the sample</li> </ul>"},{"location":"concepts/compositional_data/#log-tss-transformation","title":"Log-TSS transformation","text":"\\[ x_i^{\\log\\text{-}\\mathrm{TSS}} = \\log\\left( \\frac{x_i}{\\sum_{j=1}^{D} x_j} \\right) \\] <p>where</p> <ul> <li>\\( x_i \\) is the count of the \\(i\\)-th k-mer  </li> <li>\\( D \\) is the number of k-mers  </li> <li>the logarithm is applied element-wise</li> </ul>"},{"location":"concepts/compositional_data/#row-wise-log-normalisation","title":"Row-wise log normalisation","text":"\\[ x_i^{\\log} = \\log\\left( \\frac{x_i}{\\sum_{j=1}^{D} x_j} \\right) \\] <p>where</p> <ul> <li>\\( x_i \\) is the count of the \\(i\\)-th k-mer  </li> <li>normalization is performed independently for each sample</li> </ul> <p>(This transformation is mathematically equivalent to log-TSS?? check, either just conceptually different.)</p>"},{"location":"concepts/dimensionality_reduction/","title":"Dimensionality reduction","text":"Method Linear Local Global Scales well Typical use PCA \u2713 \u2717 \u2713 \u2713\u2713\u2713 Baseline, preprocessing t-SNE \u2717 \u2713\u2713\u2713 \u2717 \u2717 excells in local UMAP \u2717 \u2713\u2713 \u2713 \u2713\u2713 General-purpose TRIMAP \u2717 \u2713\u2713 \u2713\u2713 \u2713\u2713 global triplets PaCMAP \u2717 \u2713\u2713 \u2713\u2713 \u2713\u2713\u2713 good alround LocalMAP \u2717 \u2713\u2713 \u2713\u2713 \u2713\u2713\u2713 good alround LLE \u2717 \u2713\u2713 \u2717 \u2717 ..."},{"location":"concepts/dimensionality_reduction/#pca-principal-component-analysis","title":"PCA \u2014 Principal Component Analysis","text":"<p>Category: Linear Preserves: Global variance Scales to: Very large datasets</p>"},{"location":"concepts/dimensionality_reduction/#summary","title":"Summary","text":"<p>PCA projects the data onto orthogonal axes that maximize variance. It provides a linear approximation of the data and is often used as a baseline method or as a preprocessing step prior to nonlinear dimensionality reduction.</p> <p>In k-mer ordination, PCA captures dominant compositional gradients but may fail to represent nonlinear relationships between samples.</p>"},{"location":"concepts/dimensionality_reduction/#reference","title":"Reference","text":"<p>Pearson, K. (1901) On Lines and Planes of Closest Fit to Systems of Points in Space Philosophical Magazine DOI: 10.1080/14786440109462720</p>"},{"location":"concepts/dimensionality_reduction/#umap-uniform-manifold-approximation-and-projection","title":"UMAP \u2014 Uniform Manifold Approximation and Projection","text":"<p>Category: Nonlinear, manifold learning Preserves: Local structure, with limited global structure preservation Scales to: Large datasets</p>"},{"location":"concepts/dimensionality_reduction/#summary_1","title":"Summary","text":"<p>UMAP constructs a fuzzy topological representation of the high-dimensional data and optimizes a low-dimensional embedding that preserves local neighborhood relationships. Compared to t-SNE, UMAP generally offers better runtime performance and improved preservation of global structure.</p> <p>UMAP is well suited for large k-mer count matrices where local similarity between sequences is biologically meaningful.</p>"},{"location":"concepts/dimensionality_reduction/#reference_1","title":"Reference","text":"<p>McInnes, L., Healy, J., &amp; Melville, J. (2018) UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction arXiv  DOI: 10.48550/arXiv.1802.0342</p>"},{"location":"concepts/dimensionality_reduction/#t-sne-t-distributed-stochastic-neighbor-embedding","title":"t-SNE \u2014 t-distributed Stochastic Neighbor Embedding","text":"<p>Category: Nonlinear, probabilistic Preserves: Local structure Scales to: Small\u2013medium datasets</p>"},{"location":"concepts/dimensionality_reduction/#summary_2","title":"Summary","text":"<p>t-SNE models pairwise similarities as probability distributions and minimizes their divergence between high- and low-dimensional spaces. It excels at revealing local clusters but does not preserve global distances.</p> <p>t-SNE embeddings are sensitive to hyperparameters and random initialization.</p>"},{"location":"concepts/dimensionality_reduction/#reference_2","title":"Reference","text":"<p>van der Maaten, L., &amp; Hinton, G. (2008) Visualizing Data using t-SNE Journal of Machine Learning Research DOI: 10.48550/arXiv.2008.09237</p>"},{"location":"concepts/dimensionality_reduction/#trimap","title":"TRIMAP","text":"<p>Category: Nonlinear Preserves: Global structure with local constraints Scales to: Medium\u2013large datasets</p>"},{"location":"concepts/dimensionality_reduction/#summary_3","title":"Summary","text":"<p>TRIMAP constructs triplet constraints to preserve relative distances between points. Unlike t-SNE, TRIMAP explicitly balances local and global structure, making it suitable for exploratory analysis of large datasets.</p>"},{"location":"concepts/dimensionality_reduction/#reference_3","title":"Reference","text":"<p>Amid, E., &amp; Warmuth, M. K. (2019) TriMAP: Large-scale Dimensionality Reduction Using Triplets arXiv DOI: 10.48550/arXiv.1910.00204</p>"},{"location":"concepts/dimensionality_reduction/#pacmap-pairwise-controlled-manifold-approximation","title":"PaCMAP \u2014 Pairwise Controlled Manifold Approximation","text":"<p>Category: Nonlinear Preserves: Local, mid-range, and global structure Scales to: Large datasets</p>"},{"location":"concepts/dimensionality_reduction/#summary_4","title":"Summary","text":"<p>PaCMAP explicitly optimizes three distance regimes: near, mid-range, and far. This allows it to preserve both cluster structure and global geometry more effectively than t-SNE or UMAP in many settings.</p>"},{"location":"concepts/dimensionality_reduction/#reference_4","title":"Reference","text":"<p>Wang, Y., Huang, H., Rudin, C., &amp; Shaposhnik, Y. (2021) Understanding How Dimension Reduction Tools Work Journal of Machine Learning Research DOI: 10.48550/arXiv.2012.04456</p>"},{"location":"concepts/dimensionality_reduction/#localmap","title":"LocalMAP","text":"<p>Category: Nonlinear Preserves: Strong local structure Scales to: Medium datasets</p>"},{"location":"concepts/dimensionality_reduction/#summary_5","title":"Summary","text":"<p>LocalMAP is a variant of PaCMAP that emphasizes local neighborhood preservation. It is particularly useful when fine-scale structure is of primary interest.</p>"},{"location":"concepts/dimensionality_reduction/#reference_5","title":"Reference","text":"<p>Wang, Y., Huang, H., &amp; Rudin, C. (2021) PaCMAP and LocalMAP: Manifold Learning with Controlled Locality arXiv DOI: 10.48550/arXiv.2103.03167</p>"},{"location":"concepts/dimensionality_reduction/#lle-locally-linear-embedding","title":"LLE \u2014 Locally Linear Embedding","text":"<p>Category: Nonlinear Preserves: Local linear structure Scales to: Small datasets</p>"},{"location":"concepts/dimensionality_reduction/#summary_6","title":"Summary","text":"<p>LLE reconstructs each data point as a linear combination of its neighbors and finds a low-dimensional embedding that preserves these relationships.</p> <p>LLE is sensitive to noise and neighborhood size and is generally unsuitable for very large k-mer datasets.</p>"},{"location":"concepts/dimensionality_reduction/#reference_6","title":"Reference","text":"<p>Roweis, S. T., &amp; Saul, L. K. (2000) Nonlinear Dimensionality Reduction by Locally Linear Embedding Science DOI: 10.1126/science.290.5500.2323</p>"},{"location":"concepts/kmer_counting/","title":"what is k-mer counting","text":""},{"location":"concepts/parameter_screening/","title":"Parameter screening","text":"<p>Many nonlinear dimensionality reduction (DR) methods expose parameters that control the balance between local and global structure preservation. The optimal parameter values are data-dependent and may vary substantially with dataset size, density, and noise.</p> <p>kmer-ord therefore supports parameter screening, where multiple embeddings are generated across a predefined parameter grid instead of relying on a single configuration.</p> <p>This allows users to: - assess embedding stability - compare local vs global structure preservation - select parameters appropriate for dataset scale and analysis goals</p>"},{"location":"concepts/parameter_screening/#what-is-parameter-screening","title":"What is parameter screening?","text":"<p>Parameter screening refers to the systematic evaluation of multiple hyperparameter combinations for a given DR method.</p> <p>Rather than producing a single embedding, the algorithm generates a set of embeddings, each corresponding to a different parameter configuration.</p> <p>Each embedding is saved independently and can be inspected visually or quantitatively downstream.</p>"},{"location":"concepts/parameter_screening/#why-parameter-screening-is-important","title":"Why parameter screening is important","text":"<p>Nonlinear DR methods are inherently ill-posed: many different low-dimensional embeddings can faithfully represent aspects of the same high-dimensional data.</p> <p>Key trade-offs controlled by parameters include:</p> <ul> <li>Local vs global structure preservation</li> <li>Cluster compactness vs continuity</li> <li>Noise sensitivity</li> <li>Scalability to large datasets</li> </ul> <p>There is no universally optimal parameter setting.</p>"},{"location":"concepts/parameter_screening/#when-should-i-use-parameter-screening","title":"When should I use parameter screening?","text":"<ul> <li>Parameter screening is recommended when:</li> <li>exploring a new dataset</li> <li>embeddings appear unstable</li> <li>cluster structure is unclear</li> <li>dataset size is large or highly imbalanced</li> <li>For routine analysis, scale-aware defaults are often sufficient.</li> </ul>"},{"location":"concepts/parameter_screening/#umap-parameter-screening","title":"UMAP parameter screening","text":"<p>UMAP exposes two primary parameters that strongly affect the embedding:</p> <ul> <li><code>n_neighbors</code></li> <li><code>min_dist</code></li> </ul> <p>kmer-ord screens both parameters jointly when <code>--screen_params</code> is enabled.</p>"},{"location":"concepts/parameter_screening/#n_neighbors","title":"<code>n_neighbors</code>","text":"<p>Controls: The size of the local neighborhood used to construct the manifold graph.</p> <p>Interpretation:</p> <ul> <li>Smaller values emphasize local structure</li> <li>Larger values incorporate more global structure</li> </ul> <p>Effect on embeddings:</p> <code>n_neighbors</code> Effect Small (5\u201330) Tight local clusters, potential fragmentation Medium (50\u2013100) Balanced local and global structure Large (100\u2013200+) Smoother embeddings, improved global continuity <p>Relation to dataset size:</p> <ul> <li>Small datasets benefit from smaller <code>n_neighbors</code></li> <li>Large datasets require larger values to avoid over-fragmentation</li> </ul>"},{"location":"concepts/parameter_screening/#min_dist","title":"<code>min_dist</code>","text":"<p>Controls: The minimum distance allowed between embedded points.</p> <p>Interpretation:</p> <ul> <li>Smaller values allow points to pack tightly</li> <li>Larger values enforce separation between points</li> </ul> <p>Effect on embeddings:</p> <code>min_dist</code> Effect 0\u20130.1 Very compact clusters 0.1\u20130.3 Moderate separation 0.5\u20131.0 Emphasis on global structure <p>Key insight: <code>min_dist</code> does not change neighborhood relationships \u2014 it changes how densely points are packed in the embedding.</p>"},{"location":"concepts/parameter_screening/#interaction-between-n_neighbors-and-min_dist","title":"Interaction between <code>n_neighbors</code> and <code>min_dist</code>","text":"<p>These parameters interact strongly:</p> <ul> <li>Large <code>n_neighbors</code> + small <code>min_dist</code> \u2192 globally coherent but dense clusters</li> <li>Small <code>n_neighbors</code> + large <code>min_dist</code> \u2192 fragmented but separated structure</li> </ul> <p>Parameter screening is particularly useful because good combinations are dataset-specific.</p>"},{"location":"concepts/parameter_screening/#umap-screening-grid-in-kmer-ord","title":"UMAP screening grid in kmer-ord","text":"<p>When screening is enabled, kmer-ord evaluates the following grid:</p> <pre><code>n_neighbors \u2208 {5, 10, 50, 100, 150}\nmin_dist    \u2208 {0.0, 0.1, 0.25, 0.5, 1.0}\n</code></pre> <p>Each combination produces a separate embedding saved to disk.</p>"},{"location":"concepts/parameter_screening/#dataset-scale-and-parameter-defaults","title":"Dataset scale and parameter defaults","text":"<p>kmer-ord provides scale-aware defaults when parameter screening is disabled.</p> Dataset scale <code>n_neighbors</code> <code>min_dist</code> Rationale small 30 0.05 Emphasize fine structure medium 100 0.1 Balance local and global large 150 0.2 Stabilize global structure"},{"location":"concepts/parameter_screening/#these-defaults-are-heuristics-not-guarantees","title":"These defaults are heuristics, not guarantees.","text":"<p>Comparison with other methods</p> <p>Parameter screening is implemented for multiple DR methods, each exposing different structural trade-offs:</p> Method Screened parameters Primary structure t-SNE <code>perplexity</code>, <code>learning_rate</code> Local UMAP <code>n_neighbors</code>, <code>min_dist</code> Local + global TRIMAP <code>n_inliers</code>, <code>weight_temp</code> Global PaCMAP <code>FP_ratio</code>, <code>MN_ratio</code> Multi-scale LocalMAP <code>FP_ratio</code>, <code>n_neighbors</code> Strong local"},{"location":"concepts/parameter_screening/#t-sne","title":"t-SNE","text":"<p>t-SNE emphasizes local neighborhood preservation and is not designed to faithfully preserve global distances.</p>"},{"location":"concepts/parameter_screening/#perplexity","title":"<code>perplexity</code>","text":"<p>Controls: The effective number of neighbors considered for each point.</p> <p>Interpretation: Perplexity approximates the scale at which local structure is modeled.</p> Perplexity Effect Low (5\u201330) Very local structure, tight clusters Medium (30\u2013100) Moderate neighborhood scope High (100\u2013200+) More global coherence, risk of crowding <p>Dataset size guidance:</p> <ul> <li>Small datasets: lower perplexity</li> <li>Large datasets: higher perplexity required for stability</li> </ul> <p>Rule of thumb: <code>perplexity &lt;&lt; n_samples</code></p>"},{"location":"concepts/parameter_screening/#learning_rate","title":"<code>learning_rate</code>","text":"<p>Controls: Step size of the gradient descent optimization.</p> <p>Interpretation: Affects convergence speed and embedding stability.</p> Learning rate Effect Too small Slow convergence, poor separation Too large Instability, distorted structure <p>Parameter screening helps identify stable regions.</p>"},{"location":"concepts/parameter_screening/#trimap","title":"TRIMAP","text":"<p>TRIMAP explicitly emphasizes global structure preservation by incorporating triplet constraints.</p>"},{"location":"concepts/parameter_screening/#n_inliers","title":"<code>n_inliers</code>","text":"<p>Controls: Number of nearest neighbors treated as \u201cinliers\u201d in triplet constraints.</p> <p>Interpretation:</p> <ul> <li>Larger values incorporate broader neighborhood information</li> <li>Improves global consistency</li> </ul> <code>n_inliers</code> Effect Small Strong local structure Large Improved global layout <p>Dataset size guidance:</p> <ul> <li>Increase <code>n_inliers</code> with dataset size</li> </ul>"},{"location":"concepts/parameter_screening/#weight_temp","title":"<code>weight_temp</code>","text":"<p>Controls: Relative weighting between inlier and outlier triplets.</p> <p>Interpretation:</p> <ul> <li>Lower values emphasize local constraints</li> <li>Higher values strengthen global repulsion</li> </ul> <code>weight_temp</code> Effect Low (\u22640.3) Local emphasis Medium (0.4\u20130.6) Balanced High (&gt;1.0) Strong global structure"},{"location":"concepts/parameter_screening/#pacmap","title":"PaCMAP","text":"<p>PaCMAP is designed to preserve structure at multiple scales simultaneously.</p>"},{"location":"concepts/parameter_screening/#mn_ratio-mid-near-ratio","title":"<code>MN_ratio</code> (Mid-near ratio)","text":"<p>Controls: Proportion of mid-range neighbors relative to nearest neighbors.</p> <p>Effect:</p> <ul> <li>Stabilizes intermediate-scale structure</li> <li>Prevents over-fragmentation</li> </ul> <p>Usually kept fixed in kmer-ord.</p>"},{"location":"concepts/parameter_screening/#fp_ratio-further-point-ratio","title":"<code>FP_ratio</code> (Further point ratio)","text":"<p>Controls: Strength of repulsive forces from distant points.</p> <p>Interpretation:</p> <ul> <li>Low values \u2192 local structure</li> <li>High values \u2192 improved global separation</li> </ul> <code>FP_ratio</code> Effect Low Compact clusters High Enhanced global layout <p>Dataset size guidance:</p> <ul> <li>Increase <code>FP_ratio</code> for large datasets</li> </ul>"},{"location":"concepts/parameter_screening/#localmap","title":"LocalMAP","text":"<p>LocalMAP is a PaCMAP-derived method optimized for local neighborhood fidelity.</p>"},{"location":"concepts/parameter_screening/#n_neighbors_1","title":"<code>n_neighbors</code>","text":"<p>Controls: Neighborhood size used to define local structure.</p> <p>Effect:</p> <ul> <li>Smaller values isolate fine-scale structure</li> <li>Larger values smooth embeddings</li> </ul>"},{"location":"concepts/parameter_screening/#fp_ratio","title":"<code>FP_ratio</code>","text":"<p>Controls: Global repulsion strength.</p> <p>Interpretation:</p> <p>LocalMAP typically uses lower <code>FP_ratio</code> values than PaCMAP to avoid disrupting local continuity.</p> FP_ratio Effect Low Strong local preservation High Increased global separation"},{"location":"concepts/parameter_screening/#summary","title":"Summary","text":"<p>Parameter screening exposes the structure\u2013scale trade-off inherent to nonlinear dimensionality reduction. Rather than hiding this complexity, <code>kmer-ord</code> makes it explicit and reproducible.</p> <p>treat embeddings as exploratory models, not definitive representations.</p>"},{"location":"reference/","title":"References overview","text":"<p>Complete command-line and parameter documentation are provided for each script</p>"},{"location":"reference/#scripts","title":"Scripts","text":"<ul> <li> <p>k-mer counting</p> <p> kmer-counting.py</p> <p>Generate a k-mer count matrix from one or more FASTA files</p> <pre><code>    python kmer-counting.py \\\n    --input input.fasta \\\n    --k 6 \\\n    --output 6mer\n</code></pre> </li> <li> <p>Embedding</p> <p> kmer-ord.py</p> <p>Embed kmer counts using all DR methods with default settings</p> <pre><code>python kmer-ord.py \\\n    --input kmer_matrix.tsv \\\n    --methods all \\\n    --normalisation clr\n</code></pre> </li> </ul>"},{"location":"reference/kmer_counting/","title":"kmer-counting","text":""},{"location":"reference/kmer_counting/#overview","title":"Overview","text":"<p>Wrapper around kmer-counter for fast, read-level canonical k-mer counting from multi-FASTA files.</p> <p><code>kmer-counting.py</code> uses the external kmer-counter to compute canonical nucleotide k-mer frequency matrices at the sequence (read/contig) level, and functions as preprocessing step for downstream dimensionality reudction and binning workflows in kmer-ord.  The script outputs <code>Numpy (.npy)</code> objects that are post-processed into tab-separated TSV matrices where rows represent the sequences in the input FASTA, columns represent canonical k-mers and values represent the per-sequence k-mer counts.</p>"},{"location":"reference/kmer_counting/#usage","title":"Usage","text":"<p>Count 6-mers in sequence.fasta</p> <pre><code>python kmer-counting.py \\\n    --input sequences.fasta \\\n    --output results/ \\\n    --kmer 6 \\\n    --threads 16\n</code></pre>"},{"location":"reference/kmer_counting/#command-line-arguments","title":"Command-line arguments","text":"Parameter Flag(s) Type Default Description Input FASTA file <code>-i</code>, <code>--input</code> string required Path to multi-FASTA file containing nucleotide sequences Output directory <code>-o</code>, <code>--output</code> string required Directory where output files will be written K-mer length <code>-k</code>, <code>--kmer</code> int required Length of k-mers to count Threads <code>-t</code>, <code>--threads</code> int 1 Number of threads used for FASTA parsing (kmer-counter internal parallelism is independent)"},{"location":"reference/kmer_counting/#output","title":"Output","text":"Output type File name pattern Description K-mer count matrix <code>&lt;basename&gt;</code>.kmercount.<code>&lt;k&gt;</code>mer.matrix.tsv Per-sequence canonical k-mer count matrix Preprocessed data <code>&lt;basename&gt;</code>_preprocessed.npy NumPy array of k-mer counts (memory-mapped) Temporary files temp directory Cleaned automatically after run"},{"location":"reference/kmer_counting/#matrix-format-example","title":"Matrix format example","text":"<pre><code>Sequence_ID   AAA...   AAC...   AAG...   ...\nread_001     12        0         4\nread_002     7         2         1\n</code></pre> <ul> <li>Columns: canonical k-mers (lexicographically sorted)</li> <li>Rows: sequences from the input FASTA</li> <li>Values: <code>uint32</code> counts</li> </ul>"},{"location":"reference/kmer_counting/#canonical-k-mers","title":"Canonical k-mers","text":"<p>Canonical k-mers are computed as:</p> <pre><code>canonical(kmer) = min(kmer, reverse_complement(kmer))\n</code></pre> <p>This ensures that counts are strand invariant and feature space is reduced</p>"},{"location":"reference/kmer_counting/#performance-considerations","title":"Performance considerations","text":"<ul> <li>Optimized for large FASTA files and high-dimensional k-mer spaces</li> <li>Uses memory-mapped NumPy arrays</li> <li>Counts stored as <code>uint32</code></li> <li>Temporary directories cleaned automatically</li> </ul> <p>Memory complexity: </p> <pre><code>O(N_sequences \u00d7 N_canonical_kmers)\n</code></pre> <p>Large k-mers (k &gt; 9) can produce very large matrices, requiring a lot of memory and  disk space. Moreover large k-mers yield highly sparse matrices that are suboptimal for downstream dimensionality reduction.</p>"},{"location":"reference/kmer_counting/#benchmarking-logging","title":"Benchmarking &amp; logging","text":"<p>The script uses the internal <code>Timer</code> class to report which are stored in <code>benchmark.tsv</code>:</p> Stage Description Kmer-counter execution Time to compute k-mer counts using external binary NumPy loading Time to load <code>.npy</code> array in memory-mapped mode Header extraction Time to parse sequence IDs from FASTA Canonical k-mer generation Time to compute lexicographically sorted canonical k-mers TSV composition Time to write output TSV file Cleanup Time to delete temporary files"},{"location":"reference/kmer_counting/#external-dependencies","title":"External dependencies","text":"Type Requirement Software <code>kmer-counter</code> (Rust binary) Python version \u2265 3.8 Python packages <code>numpy</code>, <code>biopython</code> <p>Important</p> <p>The path to <code>kmer-counter</code> is hard-coded in the script:</p> <pre><code>kmer_counter_path = \".../kmer-counter\"\n\nEnsure this path is valid and executable before running.\n</code></pre> <p>Common failure causes:</p> <ul> <li>Missing or incompatible <code>kmer-counter</code> binary - check the path</li> <li>Insufficient disk space for temporary files</li> <li>very large k or extremely high sequence counts may cause memory problems</li> </ul>"},{"location":"reference/kmer_counting/#example-workflow","title":"Example workflow","text":"<pre><code>mkdir kmer_counts\npython kmer-counting.py \\ \n    --input reads.fasta \\\n    --output kmer_counts \\\n    --kmer 6 \\\n    --threads 16\n</code></pre>"},{"location":"reference/kmer_ord/","title":"K-mer Ordination (kmer-ord)","text":"<p>The script <code>kmer-ord.py</code> performs dimensionality reduction and ordination on k-mer count matrices to enable exploratory analysis and visualisation of sequence composition at read or contig level.</p> <p>The tool supports multiple normalisation strategies and multiple linear and non-linear embedding methods. It produces tabular outputs suitable for downstream visualisation and binning. Each normalisation and DR method is processed independently and produces its own outputs.</p>"},{"location":"reference/kmer_ord/#input-format","title":"Input format","text":"<p>Input matrices are derived from <code>kmer-counting.py</code>(../reference/kmer_counting.md). If derived otherwise, make sure the matrix is tab-separated (.tsv) and has the following structure: Rows represent sequences (reads, contigs), columns represent numeric k-mer counts, where the first column contains sequence identifiers. Missing values are permitted and handled during preprocessing.</p> kmer_matrix.tsv<pre><code>Sequence_ID   AAA...   AAC...   AAG...   ...\nread_001     12        0         4\nread_002     7         2         1\n</code></pre>"},{"location":"reference/kmer_ord/#basic-usage","title":"Basic usage","text":"<p>Run a single ordination method:</p> <pre><code>python kmer_ord.py \\\n    --input kmer_matrix.tsv \\\n    --methods umap \\\n    --dimension 2 \\\n    --normalisation clr\n</code></pre> <p>Run multiple methods:</p> <pre><code>python kmer_ord.py \\\n    --input kmer_matrix.tsv \\\n    --methods pca localmap umap \\\n    --normalisation clr\n</code></pre> <p>Run all supported methods:</p> <pre><code>python kmer_ord.py \\\n    --input kmer_matrix.tsv \\\n    --methods all \\\n    --normalisation clr\n</code></pre>"},{"location":"reference/kmer_ord/#command-line-arguments","title":"Command-line arguments","text":""},{"location":"reference/kmer_ord/#required-arguments","title":"Required arguments","text":"Parameter Flag(s) Type Default Description Input matrix <code>-i</code>, <code>--input</code> string required Path to the input k-mer count matrix (TSV) Methods <code>-m</code>, <code>--methods</code> list required Dimensionality reduction methods to apply <p>Supported methods: 'pca', 'kernel_pca', 'sparse_pca', 'tsne', 'umap', 'trimap', 'pacmap', 'localmap', 'lle', or 'all' For details about DR methods see Concepts: Dimensionality reduction for further details.</p>"},{"location":"reference/kmer_ord/#embedding-configuration","title":"Embedding configuration","text":"Parameter Flag Type Default Description Embedding dimensionality <code>-d</code>, <code>--dimension</code> int 2 Number of embedding dimensions (2 or 3) Random seed <code>--seed</code> int 42 Random seed for reproducibility <p>Dimensionality reduction embeddings can vary depending on the random seed, specifying a seed ensures reproducible results.</p>"},{"location":"reference/kmer_ord/#normalisation","title":"Normalisation","text":"<p>k-mer count matrices are compositional in the sense that counts depend on sequence length. Longer sequences naturally have higher counts.  To make the data suitable for ordination and downstream analysis, normalisation is recommended.  By default Centered Log-Ratio (CLR) transformation is applied, but other normalisation strategies are available and can be speficied via the <code>--normalisation</code> flag. Multiple normalisation methods may be specified separated by a space, and are applied independtly.</p> <p>Please see the Concepts: Compositional data for further details.</p> Parameter Flag Type Default Description Normalisation method(s) <code>--normalisation</code> list clr One or more normalisation strategies <p>Allowed values are <code>log_normalisation</code>, <code>clr</code>, <code>tss</code>,<code>log_tss</code> </p>"},{"location":"reference/kmer_ord/#optional-pca-pre-reduction","title":"Optional PCA pre-reduction","text":"<p>PCA may be applied prior to nonlinear embedding.</p> Parameter Flag Type Default Description Enable PCA <code>--pca_dim_red</code> flag off Apply PCA to reduce dimensions before performing the selected embedding(s) Keep variance <code>--keep_variance</code> float none Fraction of total variance to retain (e.g., 0.90, keeps 90%) Keep components <code>--keep_pcs</code> int none Number of principal components to retain <p>Note: <code>--keep_variance</code> and <code>--keep_pcs</code> are mutually exclusive.</p>"},{"location":"reference/kmer_ord/#parameter-screening","title":"Parameter screening","text":"<p>The script provides automated parameter screening to explore how different hyperparameter choices affect the resultin embeddings.  Screening focuses on parameters that control the balance between global structure preservation, which is particularly important as dataset sizes increases</p> Parameter Flag Type Default Description Screen parameters <code>--screen_params</code> flag off Run parameter sweeps instead of single embedding <p>When enabled, the script evaluates multiple parameter combinations and writes each embedding to disk. </p> <ul> <li>t-SNE screens multiple <code>perplexity</code> and <code>learning-rate</code> values  </li> <li>UMAP screens multiple <code>n_neighbors</code> and <code>min_dist</code> values  </li> <li>TRIMAP screens multiple <code>n_inliers</code> and <code>weight_temp</code> values</li> </ul> <p>Note</p> <ul> <li>parameter screening is indended for exploratory analysis!</li> <li>For routine analysis, scale-dependent presents (via <code>--scale</code>) provide reasonable hyperparameter settings without exhaustive screening.</li> <li>screening is computationally expensive for large datasets. </li> </ul>"},{"location":"reference/kmer_ord/#hyperparameter-presets-dataset-scale","title":"Hyperparameter presets ~ dataset scale","text":"<p>In addition to explicit parameter screening, the script provides predefined hyperparameter presets that adapt DR methods to different dataset sizes</p> Parameter Flag Type Default Description Dataset scale <code>--scale</code> string <code>default</code> Select a predefined hyperparameter preset <p>allowed values are <code>default</code>, <code>small</code>, <code>medium</code>, <code>large</code>, and <code>auto</code></p> <p>Each preset maps to method-specific hyperparameters that are chosen to be sensible to the corresponding dataset size (e.g. n_neighbors for UMAP, perplexity for t-SNE, or FP_ratio for PaCMAP and LocalMAP). </p> <p>when <code>--scale auto</code> is used, the scale category is inferred from the number of sequences in the input matrix:</p> <ul> <li>small: fewer than 100,000 sequences</li> <li>medium 100,000 to 1,000,000 sequences</li> <li>large: more than 1,000,000 sequences</li> </ul> <p>Note</p> <p>When screening is enabled via <code>--screen_params</code>, preset values are ignored (<code>--scale</code>), all relevant parameter combinations are evaluated and saved.</p> Method Scale Hyperparameters UMAP default <code>n_neighbors=15</code>, <code>min_dist=0.1</code> small <code>n_neighbors=30</code>, <code>min_dist=0.05</code> medium <code>n_neighbors=100</code>, <code>min_dist=0.1</code> large <code>n_neighbors=150</code>, <code>min_dist=0.2</code> t-SNE default <code>init=pca</code>, <code>random_state=42</code> small <code>perplexity=30</code>, <code>init=pca</code>, <code>random_state=42</code> medium <code>perplexity=100</code>, <code>init=pca</code>, <code>random_state=42</code> large <code>perplexity=200</code>, <code>init=pca</code>, <code>random_state=42</code> TRIMAP default <code>n_inliers=10</code>, <code>weight_temp=0.5</code> small <code>n_inliers=50</code>, <code>weight_temp=0.3</code> medium <code>n_inliers=100</code>, <code>weight_temp=0.4</code> large <code>n_inliers=150</code>, <code>weight_temp=0.5</code> PaCMAP default <code>MN_ratio=0.5</code>, <code>FP_ratio=2</code> small <code>MN_ratio=0.5</code>, <code>FP_ratio=2</code> medium <code>MN_ratio=0.5</code>, <code>FP_ratio=3</code> large <code>MN_ratio=0.5</code>, <code>FP_ratio=5</code> LocalMAP default <code>MN_ratio=0.5</code>, <code>FP_ratio=0.5</code> small <code>MN_ratio=0.3</code>, <code>FP_ratio=0.5</code> medium <code>MN_ratio=0.5</code>, <code>FP_ratio=0.7</code> large <code>MN_ratio=0.7</code>, <code>FP_ratio=1.0</code>"},{"location":"reference/kmer_ord/#output-structure","title":"Output structure","text":"<p>All outputs are written relative to the input file location.</p>"},{"location":"reference/kmer_ord/#projection-outputs","title":"Projection outputs","text":"<p>Low-dimensional projections are written to:</p> <pre><code>projections/\n</code></pre> <p>File naming pattern:</p> <pre><code>input_&lt;D&gt;D_&lt;normalisation&gt;_&lt;method&gt;_output.tsv\n</code></pre> <p>Each file contains embedding coordinates for all samples.</p> example.6mer.matrix_2D_clr_umap_output.tsv<pre><code>UMAP_1  UMAP_2\n-0.2375389  -0.24478829\n1.7667027   0.94539994\n0.41837573  1.0262766\n-1.0671473  0.011101685\n-2.5626185  -0.15495488\n-0.34270006 0.64091235\n1.0530657   -0.9450859\n-1.9106835  -1.3515233\n-0.7706668  1.2096583\n-1.4292544  -1.2981397\n</code></pre>"},{"location":"reference/kmer_ord/#preprocessed-matrices","title":"Preprocessed matrices","text":"<p>For each normalisation method, the preprocessed feature matrix is saved as:</p> <pre><code>input_&lt;normalisation&gt;_preprocessed.npy\n</code></pre> <p>These files store the transformed matrices used for embedding.</p>"},{"location":"reference/kmer_ord/#parameter-screening-outputs","title":"Parameter screening outputs","text":"<p>When parameter screening is enabled, results are written to method-specific directories:</p> <pre><code>input.tsv_umap_parameter_screening  \ninput.tsv_tsne_parameter_screening  \ninput.tsv_trimap_parameter_screening  \n</code></pre> <p>Each file corresponds to a single parameter combination.</p>"},{"location":"reference/kmer_ord/#notes","title":"Notes","text":"<ul> <li>Large k-mer matrices may require substantial memory  </li> <li>PCA pre-reduction is recommended for large datasets  </li> <li>Parameter screening can generate many output files</li> </ul>"},{"location":"reference/kmer_ord/#related-documentation","title":"Related documentation","text":"<ul> <li>Concepts: k-mer manifolds and normalisation strategies  </li> <li>Tutorials: end-to-end ordination and visualisation workflows</li> </ul>"},{"location":"tutorials/","title":"tutorials index page","text":""}]}